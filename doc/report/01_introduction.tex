\section{Introduction}\label{sec:intro}

This report is the result of a project in the course ''Design of Parallel and High Performance Computing'' at ETH Z\"urich. The goal of the project was to develop a parallel implementation of an important algorithm or application, that scales well in a multicore environment. This report describes an approach to process large XML files or data streams in parallel using the query language XPath.

\mypar{Motivation} Nowadays, in the age of the internet of things and social media, where a lot and continuous information is being generated and every single person has the opportunity to share their thoughts and insights, a huge content of valuable information is available. One of these examples is the Twitter Firehose, which generates an output of all tweet being made in real time. The data stream may reach an output rate of 3 Gbps and more on  its peak, therefore to process this data in real time requires high computational power.

To achieve the necessary processing power, one can use a multicore chip, that provides several processing units, that work in parallel. While dealing with such a datastream or data file in sequential is trivial and straight-forward, an implementation in parallel is not as simple. The data formats used are mostly context-free languages, such as XML or JSON. To operate on the stream in parallel, it must be splitted into similar chunks and distributed to each core. Ideally, these chunks are well-formed and self-contained, such that no processing unit requires to exchange any information with other units. To generate well-formed chunks, parsing and preprocessing the data beforehand sequentially is necessary. As this might pose a bottleneck for parallel and high-performance query matching on XML data, in our approach we try to avoid any preprocessing on the raw data. Thus we had to find a way, in which each unit is able to operate on its chunk without any additional information from its peers.

Our implementation focuses on XML query matching, using XPath. Our platform of choice is the Intel's Xeon Phi, incorporating 61 cores and 16 GB of memory. We found a scalable approach to process queries on large XML files. Our implementation reaches a throughput of about 0.93 GB/s and offers a big potential for optimization to the architecture at use. 

\mypar{Related work} Main inspiration of our work was \cite{Ogden2013}. Ogden et al describe an approach to query XML data with the help of pushdown transducers. Its core idea is to generate mappings of a start state and an end state. For each chunk one mapping is being computed and then, when each core has finished processing its part, they are merged according to the matching end and start states of each chunk.

Optimally to process XML streams, deterministic automatons are used. The compilation of XPath queries into automatons is discussed in \cite{Green2004}.