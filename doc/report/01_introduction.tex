\section{Introduction}\label{sec:intro}

In this report we describe the results of our project that was part of the
course ''Design of Parallel and High Performance Computing'' at ETH Z\"urich.
The goal of the project was to develop a parallel implementation of an important
algorithm or application, that scales well in a multicore environment. This
report describes an approach to process large XML files or data streams in
parallel using the XPath query language.

XML is most commonly used as an interoperable data exchange format and plays 
an important role in a wide variety of fields, from document formats, such as the 
Open Document Format \todo{ref} and/or (X)HTML \todo{ref} to various kinds of
configuration file formats. All of these applications have in common that XML is
primarily used as a general tool to persist and restore the dynamic state of an
application or program.

Following the on-going trend towards big data, however, XML has also been used
to make large amounts of structured data available as high throughput streams.
One such example is Twitter Firehose which makes all user generated tweets
available trough a single XML-Stream\footnote{Twitter has changed the document
format from XML to JSON. We want to point out that the techniques presented in this
report can easily be adapted to work with almost any structured data exchange
format.}. Twitter Firehose reaches a throughput of up to 3 Gbps.

Most off-the-shelf processing tools are single-threaded and are not tailored towards 
the stream processing applications mentioned above. Processing structured data at 
such a high throughput, however, only becomes possible by leveraging the power of 
multi processor systems. As parsing is an inherently sequential process, this requires 
the careful orchestration of parallel processors.

Ideally, the data can be split into chunks, such that it can be processed independently.
In our approach we achieve this by using a compression that is agnostic of the
internal structure of the XML data. Subsequently, the XPath query matching is done 
using only the compressed data.

Our implementation focuses on XML query matching using XPath. It is written in
C/C++ and our platform of choice is the Intel's Xeon Phi \cite{IntelXeon}, incorporating 61 cores
and 16 GB of memory. We found a scalable approach to process queries on large
XML files. Our implementation reaches a throughput of about 0.29 GB/s and offers
a big potential for optimization to the architecture at use. 

\mypar{Related work} Main inspiration of our work was \cite{Ogden2013}. Ogden et
al describe an approach to query XML data with the help of pushdown transducers.
Its core idea is to split the data stream into different chunks, then for every chunk to generate state mappings. These states correspond to the states in the transducer. As the XML chunks are not well-formed, each potential starting and ending state of the snippet must be estimated. These mappings must then be merged into one sequence of states, which then forms the state transition order of the transducer. In this sequence all accepting states are being extracted, which correspond to the queries matching a certain part of the XML.

Optimally to process XML streams, deterministic automatons are used. The
compilation of XPath queries into automatons is discussed in \cite{Green2004}.


%\mypar{Motivation} Nowadays, in the age of the internet of things and social
%media, where a lot and continuous information is being generated and every
%single person has the opportunity to share their thoughts and insights, a huge
%content of valuable information is available. One of these examples is the
%Twitter Firehose, which generates an output of all tweet being made in real
%time. The data stream may reach an output rate of 3 Gbps and more on  its peak,
%therefore to process this data in real time requires high computational power.
%
%To achieve the necessary processing power, one can use a multicore chip, that
%provides several processing units, that work in parallel. While dealing with
%such a datastream or data file in sequential is trivial and straight-forward, an
%implementation in parallel is not as simple. The data formats used are mostly
%context-free languages, such as XML or JSON. To operate on the stream in
%parallel, it must be splitted into similar chunks and distributed to each core.
%Ideally, these chunks are well-formed and self-contained, such that no
%processing unit requires to exchange any information with other units. To
%generate well-formed chunks, parsing and preprocessing the data beforehand
%sequentially is necessary. As this might pose a bottleneck for parallel and
%high-performance query matching on XML data, in our approach we try to avoid any
%preprocessing on the raw data. Thus we had to find a way, in which each unit is
%able to operate on its chunk without any additional information from its peers.

