\section{Introduction}\label{sec:intro}

This report is the result of a project in the course ''Design of Parallel and High Performance Computing''. The goal of the project was to develop a parallel implementation of an important algorithm or application, that scales well in a multicore environment. This report describes an attempt to process large XML files or data streams in parallel using the query language XQuery.

\mypar{Motivation} Nowadays, in the age of the internet of things, where a lot and continuous information is being generated and in the age of social media, where every single person has the opportunity to share their thoughts and insights, a huge content of valuable information is available. One of these examples is the Twitter Firehose, which generates an output of all tweet being made in real time. The data stream may reach an output rate of 3 Gbps and more on  its peak, therefore to process this data in real time requires high computational power.

To achieve the necessary processing power, one can use a multicore chip, that provides several processing units, that work in parallel. While dealing with a datastream or data file sequentially is trivial and straight-forward, an implementation in parallel is not as simple. The data formats used are mostly context-free languages, such as XML or JSON. To operate on the stream in parallel, it must be splitted into similar chunks and distributed to each core. Ideally, these chunks are well-formed and self-contained, such that no processing unit needs information from another unit. In our approach for high-performance query matching on XML data, we want to avoid preprocessing the data stream. To actually generate well-formed chunks, parsing the data would be necessary. Thus we must find a way, that either each core can operate individually on its chunk without needing the information of its peers, or that it does not need to know any additional information at all to process it.

Our implementation focuses on XML query matching, using XQuery. Our platform of choice is the Intel's Xeon Phi, incorporating 61 cores and 16 GB of memory. We found a scalable approach, to process these queries on large XML files. Our implementation reaches a throughput of about 0.93 GB/s and offers a big potential to be optimized to the architecture at use. 

\mypar{Related work} Main inspiration of our work was \cite{Ogden2013}. Ogden et al describe an approach to query XML data with the help of pushdown transducers. Its core idea is to generate mappings of a start state and an end state. For each chunk one mapping is being computed and then, when each core has finished processing its part, they are merged according to the matching end and start states of each chunk.
%TODO
TBD!
