
\section{Experimental Results}\label{sec:exp}

\begin{figure}
    \includegraphics[scale=.45]{img/def/tokenizer_tp_total.eps}
    \includegraphics[scale=.45]{img/def/tokenizer_tp_per_thread.eps}
    \caption{Total throughput and throughput per thread of the tokenizer
    for a 2GB input file.}
    \label{fig:tokenizertp}
\end{figure}

\begin{figure}
      \includegraphics[scale=.45]{img/def/matcher_tp_total.eps}
      \includegraphics[scale=.45]{img/def/matcher_tp_per_thread.eps}
    \caption{Total throughput and throughput per thread of the matcher 
    for a 2GB input file.}
      \label{fig:matchertp}%
\end{figure}

\begin{figure}
    \includegraphics[scale=.45]{img/def/matcher_tp_compare.eps}
    \caption{Throughput of the matcher for different file sizes.}
    \label{fig:tkmatchercomp}
\end{figure}

\begin{figure}
    \includegraphics[scale=.45]{img/def/tokenizer_sim.eps} 
    \caption{Experimental program simulating memory access pattern of the
    tokenizer.}
    \label{fig:tokenizersim}
\end{figure}


In the following we present our experimental results. We only measured the
performance of the tokenizer and the matcher, as all other parts of the system
are I/O bound.

\mypar{Experimental Setup} The experiments were conducted on an Intel Xeon Phi
7120 coprocessor, containing 61 cores and 16 GB of GDDR5 memory with a
theoretical bandwidth of 352 GBps. For compilation the Intel Compiler version
15.0.0 20140723 was used with the following flags: \verb;-fopenmp;
\verb;-std=c++11; \verb;-mmic; \verb;-Wall; \verb;-qopt-report3; \\
\verb;-qopt-report-phase=vec; \verb;-O3;.

To generate test data, we used the XML benchmark project XMark
\cite{Schmidt2002}. As input a 2 GB XML file was used containing 61'113'640
tags. 

\mypar{Results} We measured the performance of the tokenizer for 1, 2, 4, 8, 16,
32, 60, 120, 180 and 240. Each experiment was run ten times. The results were
built with the average of these runs. Figure \ref{fig:tokenizertp} shows both,
the total throughput and the throughput per thread.

The experiments reveal clearly, that the throughput of the tokenizer increases
with the number of threads. While the benefits of more threads are significant
up to 120 threads, i.e. two threads per core, less performance can be gained
from 120 up to 240 threads.

For the matcher, the number of threads is equal to the number of queries. Hence,
to asses the performance, we tested on the same 2GB file with 1, 2, 4, 8, 16,
32, 60, 120, 180 and 240 queries. Since the performance of the matcher depends
solely on the tokenstream and not on the original input data, the throughput for
the matcher is stated in tokens per second. Again, the result is the average of
ten runs (see Figure \ref{fig:matchertp}).

Until up to 60 queries the decrease in throughput is less than 20\%, while with
120 queries and more the throughput decreases significantly. Hence, weak scaling
is observable for up to 60 threads. If the number of threads exceeds the number
of cores, the performance suffers. This is in line with the observation Fang et
al. made in \cite{Fang14}.

To further asses the performance of the matcher, we included different file
sizes (see Figure \ref{fig:tkmatchercomp}). We assume that the decrease in
performance for 8 GB is due to the fact that it is more likely for large files
that different threads access different memory areas while using the same cache
directory.

The total throughput of the tokenizer and matcher running with 120 threads is
0.29 GBps. This is far below the specified maximum memory bandwidth of 352
GBps. To make a realistic assessment of the maximally achievable throughput
we conducted an experiment with a dummy program which has a similar memory
access pattern as our tokenizer: A contiguous block of memory is read byte-wise
and every 80 bytes (based on the average number of tags per file) 10 bytes are
written to memory. The results are shown in Figure ~\ref{fig:tokenizersim}.
