\section{Tokenstream}\label{sec:yourmethod}

\todo{pptranducer} 

\subsection{Overview}

The method that we propose can be viewed as a batch processing system consisting
of three components (Figure \todo{Figure}):

\begin{enumerate}
\item The chunker,
\item the tokenizer, and
\item the matcher.
\end{enumerate}

First, a \emph{Query Transformer} analyzes the query and produces a token
mapping and a state table describing a push-down automaton for each XPath
expression in the query.

The \emph{chunker} splits the XML streams into chunks of approximately equal
size. Tags are not split, the structure of the XML data contained in the
individual chunks can be arbitrary. The \emph{tokenizer} then compresses each
XML chunk into a tokenstream chunk, using the token mapping generated by the
query transformer to map tag names to token ids. Connected together, these
tokenstream chunk form the tokenstream. In the \emph{matcher}, the push-down
automatons are run in parallel over the entire tokenstream to identify matching
nodes.

The aim of our method is to reduce memory traffic in the matching phase, as the
tokenstream takes up less memory than the original XML stream. Workloads are
divided differently in the tokenizer and in the matcher. Our method is
successful if we can show \emph{strong scaling} for the tokenizer and \emph{weak
scaling} for the matcher.

\subsection{Query Transformer}

The query transformer takes as input an XPath query which takes the form of a
text file containing one or more XPath expression. The query transformer outputs
two text files: a token mapping file and a file containing the state tables of
the push-down transducers, one for each path expression in the input file.

A token mapping is simply a unique list that contains all tag names appearing in
any of the path expressions. The token number that corresponds to the tag name
is the line number of the tag name in the token mapping file. The push-down
automatons operate use these token numbers as input alphabet, and consequently
they act as offset in the state table of the push-down automatons.

The push-down automatons are generated using the methods presented in
\texttt{xml processing paper}: Each path expression is turned into an individual
query tree. This query tree is in turn used to generate a non-deterministic
automaton which is then transformed into a deterministic automaton using
the standard power set method described in \todo{ulman reference}.

\subsection{Chunker}

The chunker splits the input XML file into chunks of approximately equal size.
The minimum size of a chunk is determined by dividing the size of the XML
document by the number of available threads in the tokenizer. The first chunk
starts the beginning of the XML stream. The start of the following chunk is
determined by adding the minimum chunk size to the current position and
searching for the next less-than-sign ('\texttt{<}')â€“these offsets accumulate over
all chunks, rendering the last chunk smaller than the minimum chunk size, but we
assume that the effects of this are negligible for our considerations.

Similar to \todo{transducer} we ignore \texttt{CDATA}-sections and comments for
simplicity. The authors of \todo{transducer} suggest extending the transducer to
accommodate the possibility that a chunk starts withing a comment or a
\texttt{CDATA}-section. Similarly, in our case, the tokenizer would just have to
produce tokens for the start and end of comments and \texttt{CDATA}-sections.

\subsection{Tokenizer}



%Now comes the ``beef'' of the report, where you explain what you
%did. Again, organize it in paragraphs with titles. As in every section
%you start with a very brief overview of the section.

%In this section, structure is very important so one can follow the technical content.

%Mention and cite any external resources that you used including libraries or other code.
