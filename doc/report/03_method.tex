\section{Tokenstream}\label{sec:yourmethod}

\todo{pptranducer} 

\subsection{Overview}

The method that we propose can be viewed as a batch processing system consisting
of three components (Figure \todo{Figure}):

\begin{enumerate}
\item The chunker,
\item the tokenizer, and
\item the matcher.
\end{enumerate}

First, a \emph{Query Transformer} analyzes the query and produces a token
mapping and a state table describing a push-down automaton for each XPath
expression in the query.

The \emph{chunker} splits the XML streams into chunks of approximately equal
size. Tags are not split, the structure of the XML data contained in the
individual chunks can be arbitrary. The \emph{tokenizer} then compresses each
XML chunk into a tokenstream chunk, using the token mapping generated by the
query transformer to map tag names to token ids. Connected together, these
tokenstream chunk form the tokenstream. In the \emph{matcher}, the push-down
automatons are run in parallel over the entire tokenstream to identify matching
nodes.

The aim of our method is to reduce memory traffic in the matching phase, as the
tokenstream takes up less memory than the original XML stream. Workloads are
divided differently in the tokenizer and in the matcher. Our method is
successful if we can show \emph{strong scaling} for the tokenizer and \emph{weak
scaling} for the matcher.

\subsection{Query Transformer}

The query transformer takes as input an XPath query which takes the form of a
text file containing one or more XPath expression. The query transformer outputs
two text files: a token mapping and a file containing the state tables of
the push-down transducers, one for each path expression in the input file.

A token mapping is simply a unique list that contains all tag names appearing in
any of the path expressions. The token number that corresponds to the tag name
is the line number of the tag name in the token mapping file. The push-down
automatons operate use these token numbers as input alphabet, and consequently
they act as offset in the state table of the push-down automatons.

The push-down automatons are generated using the methods presented in
\texttt{xml processing paper}: Each path expression is turned into an individual
query tree. This query tree is in turn used to generate a non-deterministic
automaton which is then transformed into a deterministic automaton using
the standard power set method described in \todo{ulman reference}.

\subsection{Chunker}

The chunker splits the input XML file into chunks of approximately equal size.
The minimum size of a chunk is determined by dividing the size of the XML
document by the number of available threads in the tokenizer. The first chunk
starts the beginning of the XML stream. The start of the following chunk is
determined by adding the minimum chunk size to the current position and
searching for the next less-than-sign ('\texttt{<}')â€“these offsets accumulate over
all chunks, rendering the last chunk smaller than the minimum chunk size, but we
assume that the effects of this are negligible for our considerations.

Similar to \todo{transducer} we ignore \texttt{CDATA}-sections and comments for
simplicity. The authors of \todo{transducer} suggest extending the transducer to
accommodate the possibility that a chunk starts withing a comment or a
\texttt{CDATA}-section. Similarly, in our case, the tokenizer would just have to
produce tokens for the start and end of comments and \texttt{CDATA}-sections.

\subsection{Tokenizer and Tokenstream}

The tokenizer maps tag names onto corresponding token nubmers according to the
token mapping generated by the query transformer: A top-down parser parses the
XML and whenever an opening or closing tag is found, the tag name is compared
with a list of known tag names from the token mapping. For closing tags, the
token number is negated. All unknown opening (closing) tags are mapped onto
the token number $n+1$ ($-(n+1)$).

For example, consider an XML chunk \verb;<a><c></c></a>; and a token mapping
containing only the tag names \verb;a; and \verb;b; in this order. The
aforementioned XML chunk would be translated into the token stream $1, 3, -3,
-1$.

In our implementation, the token numbers are encoded as 16-bit wide signed
integers which seemed like a good compromise. This seemed to be reasonable
trade-off between the number of different tag names ($2^15-2$) that can be
represented and size. Note that the token size can in principle also be decided
dynamically based on the size of the token mapping.

\subsection{Matcher}

The matcher runs each push down automaton in a separate thread. Hence, the
number of threads is equal to the number of path expressions in the original
XPath query. As soon as a push-down automaton transitions into an accepting
state, the offset of the matching token is written into an output list.
Together with the offset stream, this allows the extraction the matching nodes
from the original XML stream.

Our implementation only outputs the byte offset of the matching nodes.

%Now comes the ``beef'' of the report, where you explain what you
%did. Again, organize it in paragraphs with titles. As in every section
%you start with a very brief overview of the section.

%In this section, structure is very important so one can follow the technical content.

%Mention and cite any external resources that you used including libraries or other code.
